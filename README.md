# NBA Champ Predictor - Machine Learning Model

This project is designed to predict the NBA champion by leveraging neural networks and historical data using TensorFlow and Python. The dataset encompasses various team attributes, including performance metrics like field goals attempted and percentages, three-pointers made and attempted, among others. The target variable indicates team success within a specific year, denoting 0 for non-championship years and 1 for championship years.

## Overview

The project consists of several functions to import data from CSV files, train a neural network model, and make predictions based on user input.

## Installation

Clone this repository to your local machine using:

`git clone https://github.com/your_username/sports-data-prediction.git`

## Files

- `main.py`: The main Python script that imports data, trains the model, and makes predictions.
- `data/`: Directory containing CSV files with historical team data.

## Dependencies

- csv
- datetime
- os
- random
- numpy
- tensorflow

### Install dependencies using:

```bash
pip install -r requirements.txt
```

## Usage

To use this project, follow these steps:

1. Make sure you have Python installed on your system.
2. Clone this repository to your local machine.
3. Install the required dependencies by running `pip install -r requirements.txt`.
4. Run the script `main.py`.
5. Follow the prompts to enter the prediction year.
6. View the prediction generated by the model.

## Functions

### 1. `import_data(excluded_year)`

Imports sports data for multiple years, excluding a specified year.

### 2. `import_prediction(excluded_year)`

Imports data for prediction from a specified year.

### 3. `train_model(excluded_year)`

Trains a neural network model using the imported data.

### 4. `get_user_input()`

Prompts the user for input regarding the prediction year.

### 5. `get_predictions(prediction_year)`

Returns the predictions based on user input.

### 6. `print_best_team(prediction_year, predictions)`

Prints the team with the maximum predicted value for a given prediction year.

## Model Training

1. The script imports data using the provided functions.
2. The data is converted to NumPy arrays and normalized using TensorFlow's Normalization layer.
3. A Sequential model is defined with two Dense layers.
4. The model is compiled with a binary cross-entropy loss function and Adam optimizer.
5. The model is trained using the training data and target values.

Feel free to modify the script and parameters based on your specific use case and dataset.
